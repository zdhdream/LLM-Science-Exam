{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90089c05",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-09T10:26:25.132401Z",
     "iopub.status.busy": "2023-09-09T10:26:25.131267Z",
     "iopub.status.idle": "2023-09-09T10:26:54.446628Z",
     "shell.execute_reply": "2023-09-09T10:26:54.444507Z"
    },
    "papermill": {
     "duration": 29.324928,
     "end_time": "2023-09-09T10:26:54.450007",
     "exception": false,
     "start_time": "2023-09-09T10:26:25.125079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install faiss-gpu\n",
    "# # !pip install faiss-cpu\n",
    "# !pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aeb8f8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T10:26:54.469441Z",
     "iopub.status.busy": "2023-09-09T10:26:54.469104Z",
     "iopub.status.idle": "2023-09-09T10:27:01.148608Z",
     "shell.execute_reply": "2023-09-09T10:27:01.147634Z"
    },
    "papermill": {
     "duration": 6.690856,
     "end_time": "2023-09-09T10:27:01.151033",
     "exception": false,
     "start_time": "2023-09-09T10:26:54.460177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.12.1\n",
      "transformers.__version__: 4.18.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "pd.set_option('display.max_columns', None)\n",
    "from tqdm.auto import tqdm\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import blingfire as bf\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import util\n",
    "import tokenizers\n",
    "import transformers\n",
    "\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import get_cosine_schedule_with_warmup, DataCollatorWithPadding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "model = \"model/gte-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "device = torch.device('cuda:1') if torch.cuda.device_count() > 1 else torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ba6390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "class WeightedLayerPooling(nn.Module):\n",
    "    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights=None):\n",
    "        super(WeightedLayerPooling, self).__init__()\n",
    "        self.layer_start = layer_start\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.layer_weights = layer_weights if layer_weights is not None \\\n",
    "            else nn.Parameter(\n",
    "            torch.tensor([1] * (num_hidden_layers + 1 - layer_start), dtype=torch.float)\n",
    "        )\n",
    "\n",
    "    def forward(self, all_hidden_states):\n",
    "        all_layer_embedding = all_hidden_states[self.layer_start:, :, :, :]\n",
    "        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n",
    "        weighted_average = (weight_factor * all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n",
    "        return weighted_average\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "            # self.config.hidden_dropout = 0.\n",
    "            # self.config.hidden_dropout_prob = 0.\n",
    "            # self.config.attention_dropout = 0.\n",
    "            # self.config.attention_probs_dropout_prob = 0.\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        # if self.cfg.gradient_checkpointing:\n",
    "        #     self.model.gradient_checkpointing_enable\n",
    "\n",
    "        self.pool = MeanPooling()\n",
    "        self.fc_dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1)\n",
    "        self._init_weights(self.fc)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n",
    "        # feature = F.normalize(feature, p=2, dim=1)\n",
    "        return feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9acf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"output_simcse_model\"\n",
    "model = CustomModel(cfg=None, config_path=MODEL_NAME + '/config.pth', pretrained=False)\n",
    "state = torch.load(MODEL_NAME + '/model-gte-small_fold0_best.pth', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state['model'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05555bfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T10:27:01.193262Z",
     "iopub.status.busy": "2023-09-09T10:27:01.192416Z"
    },
    "papermill": {
     "duration": 6145.958489,
     "end_time": "2023-09-09T12:09:27.142277",
     "exception": false,
     "start_time": "2023-09-09T10:27:01.183788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca7cd8b332e4f47bd6292f79a0588b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)2e6d8/.gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029c2d06675d4963beacb4d2e08e633a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d710840aebbe4535bf563a446b21aad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)9e0ce2e6d8/README.md:   0%|          | 0.00/68.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4adbc5f3e5a24ef39ade54994a23bcc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)0ce2e6d8/config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29188aa5665747c299abea4ebdb80597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/66.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b9da153e6144eebf0f6bcd3fcce222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae8b60bbaac4b3cb1ab0afb4c2037a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b09a49f2d97400c831cffdcf3f34cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)2e6d8/tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8c6809dd8647b5bca35bc2b9249c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad87b6209865453888800aade0e70a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)9e0ce2e6d8/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb8355f1673407eb513e9b676b59486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce2e6d8/modules.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file_id: 1 - file_name: a.parquet ......\n",
      "Index(['id', 'title', 'text', 'categories'], dtype='object')\n",
      "Sample text:  A & B High Performance Firearms was a competition pistol manufacturer. Products included the \"Limited Class\" and \"Open Class\" semi-automatic pistols, both available in .40 S&W; and .45 ACP. A & B sold directly to consumers. ==References== ==External links== Category:Defunct firearms manufacturers Category:Defunct manufacturing companies based in California\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78b4061b722433c9e1e5d2598343d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/13836 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faiss index saved to '/kaggle/working/wikipedia_embeddings_collection_1_a.index'\n",
      "Processing file_id: 2 - file_name: b.parquet ......\n",
      "Index(['id', 'title', 'text', 'categories'], dtype='object')\n",
      "Sample text:  B & B Hospital (Baidya and Banskota Hospital) is a private hospital with the goal to provide health services to the community of Nepal founded in 1997. The hospital was established in 1977 in order to provide an extensive and affordable service to the community. B&B; was established by Dr. Jagdish Lal Baidya and Dr. Ashok K. Banskota. It is located over 2.26 acres and includes an educational wing called B&B; Medical Institute. B&B; Hospital's goal is to provide efficient healthcare in the country with many departments such as orthopedics, general surgery and urology, general medicine, plastic/cosmetic & maxillofacial surgery, gynecology and obstetrics, neuroscience, pediatrics, otorhinolaryngology, cardiology, oncology, cardiothoracic & vascular surgery, dental, psychiatry, dermatology & venereology, nephology, ophthalmology, pneumatology, anesthesiology, and nutrition. B&B; Hospital is known for their orthopedic, urological/surgical expertise. Employed at B&B; Hospital are 120 professional doctors and 500+ staff members. Patients can choose from several health packages including: women's health package for age below 40, women's health package for age above 40, men's health package, gold health package for male, gold health package for female above 40, gold health package for female below 40, basic women's health package, and basic health package. == Services == Services provided range from emergency and trauma care, outpatient department, in patient services, OT and surgical services, clinical laboratory, pharmacy, sociotherapy, optical diagnostics services, and radiology and imaging services. * Department of Orthopaedic Surgery- services include joint replacement surgery, arthroscopy and sports medicine, spine surgery and spinal deformity correction, paediatric orthopaedics, arm and hand surgery. * General Surgery and Urology- provides urology and laparoscopic services, as well as general surgery procedures. * General Medicine- services include upper gastrointestinal endoscopy, colonoscopy, ERCP, haemodialysis, peritoneal dialysis, pulmonary function testing. * Plastic, Cosmetic and Maxilloficial Surgery- microvascular surgery, reconstructive, aesthetic and cosmetic operations are performed, as well as maxillofacial operations that manage simple to complex facial bone fractures. * Gynaecology and Obstetrics- the department deals with all obstetric emergencies, including prenatal and antenatal care, normal and abnormal deliveries, as well as providing safe abortion services, family planning and counseling services. All gynaecological procedures are performed, including laparoscopic major gynaecological surgery, colposcopy, hysterectomy and uro-gynaecological operations. * Neuroscience- the department is equipped to handle all kinds of head and spinal problems, such as various traumas, tumors, congenital anomalies, vascular problems, etc. The department is also involved in the hospital's academic activities. * Paediatrics-the department provides care for newborns admitted with cases like AGE, pneumonia, meningitis, etc. * ENT- departmental services include microsurgery of the ear, surgery of the nose and the throat, head and neck surgery. * Cardiology- services include emergency management and intensive care, cardiac catheterization, blood pressure and heart rhythm monitoring, angiography, angioplasty & stenting, device implantation, peripheral interventions, echocardiography and color doppler. * Oncology- the hospital's cancer centre provides medical and surgical treatment to patients, including daily OPD consultations, chemotherapy, treatment planning and surgical procedures. * Cardiothoracic and Vascular Surgery * Dental * Psychiatry * Dermatology and Venereology- active in both academic and research activities, the department offers consultations for skin and sexually transmitted diseases and cosmetological problems, allergo-diagnostic tests, electro- catheterization, mole excision and skin biopsies. * Nephrology- the services offered include OPD, pre- and post-transplant follow up, and haemodialysis. * Ophthalmology * Rheumatology * Anesthesiology * Nutrition & Dietetics * Dermatology & Venerology ==References== 5\\. Hospital Site Category:Hospital buildings completed in 1997 Category:Hospitals in Nepal Category:Hospitals established in 1997 Category:1997 establishments in Nepal\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a669f368df7a4fe98d8e57f7ee2a0162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10206 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faiss index saved to '/kaggle/working/wikipedia_embeddings_collection_2_b.index'\n",
      "Processing file_id: 3 - file_name: c.parquet ......\n"
     ]
    }
   ],
   "source": [
    "model_name = \"model/e5-base-v2/\"\n",
    "sentence_transformer = SentenceTransformer(model_name)\n",
    "parquet_folder = \"\"\n",
    "\n",
    "file_names = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'number', 'o', 'other', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "for idx, filename in enumerate(file_names):\n",
    "    if (idx + 1) >= 1:\n",
    "        document_embeddings = []\n",
    "\n",
    "        print(f\"Processing file_id: {idx + 1} - file_name: {filename}.parquet ......\")\n",
    "\n",
    "        parquet_path = os.path.join(parquet_folder, f\"{filename}.parquet\")\n",
    "        df = pd.read_parquet(parquet_path)\n",
    "\n",
    "        print(df.columns)\n",
    "        print(\"Sample text: \", df.iloc[0][\"text\"])\n",
    "\n",
    "        sentences = df[\"text\"].tolist()\n",
    "        embeddings = sentence_transformer.encode(sentences, normalize_embeddings=True)\n",
    "        document_embeddings.extend(embeddings)\n",
    "\n",
    "        del df\n",
    "\n",
    "        document_embeddings = np.array(document_embeddings).astype(\"float32\")\n",
    "        index = faiss.IndexFlatIP(document_embeddings.shape[1])\n",
    "        index.add(document_embeddings)\n",
    "        faiss_index_path = f\"/kaggle/working/wikipedia_embeddings_collection_{idx + 1}_{filename}.index\"\n",
    "        faiss.write_index(index, faiss_index_path)\n",
    "\n",
    "\n",
    "        print(f\"Faiss index saved to '{faiss_index_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ead24af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T06:58:55.393190Z",
     "iopub.status.busy": "2023-09-09T06:58:55.392623Z",
     "iopub.status.idle": "2023-09-09T06:58:55.404821Z",
     "shell.execute_reply": "2023-09-09T06:58:55.403761Z",
     "shell.execute_reply.started": "2023-09-09T06:58:55.393156Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# index_folder1 = \"/kaggle/input/wikipedia-embeddings\"\n",
    "# index_folder2 = \"/kaggle/input/wikipedia-faiss-index\"\n",
    "\n",
    "# file_names = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'number', 'o', 'other', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "# merged_index = faiss.IndexFlatL2(384)\n",
    "# for idx, filename in enumerate(file_names):\n",
    "#     if (idx + 1) >= 7:\n",
    "#         break\n",
    "    \n",
    "#     if (idx + 1) >= 12 and (idx + 1) <= 20:\n",
    "#         indexname = f\"wikipedia_embeddings_collection_{idx + 1}_{filename}.index\"\n",
    "#         print(f\"Merge file {idx + 1} - {indexname}\")\n",
    "#         index = faiss.read_index(os.path.join(index_folder2, indexname))\n",
    "\n",
    "#         num_vectors = index.ntotal\n",
    "#         for i in range(num_vectors):\n",
    "#             vec = index.reconstruct(i).reshape(-1, 384)\n",
    "#             vec = np.array(vec).astype(\"float32\")\n",
    "#             merged_index.add(vec)\n",
    "            \n",
    "#     else:\n",
    "#         indexname = f\"wikipedia_embeddings_collection_{idx + 1}_{filename}.index\"\n",
    "#         print(f\"Merge file {idx + 1} - {indexname}\")\n",
    "#         index = faiss.read_index(os.path.join(index_folder1, indexname))\n",
    "\n",
    "#         num_vectors = index.ntotal\n",
    "#         for i in range(num_vectors):\n",
    "#             vec = index.reconstruct(i).reshape(-1, 384)\n",
    "#             vec = np.array(vec).astype(\"float32\")\n",
    "#             merged_index.add(vec)\n",
    "            \n",
    "#     if (idx + 1) == 6:\n",
    "#         merged_index_path = \"/kaggle/working/merged_1.index\"\n",
    "#         faiss.write_index(merged_index, merged_index_path)\n",
    "\n",
    "#         print(f\"Merged index saved to '{merged_index_path}'\")\n",
    "        \n",
    "#         del merged_index\n",
    "\n",
    "        \n",
    "# merged_index = faiss.IndexFlatL2(384)\n",
    "# for idx, filename in enumerate(file_names):\n",
    "#     if (idx + 1) <= 6:\n",
    "#         continue\n",
    "        \n",
    "#     if (idx + 1) == 13:\n",
    "#         break\n",
    "    \n",
    "#     if (idx + 1) >= 12 and (idx + 1) <= 20:\n",
    "#         indexname = f\"wikipedia_embeddings_collection_{idx + 1}_{filename}.index\"\n",
    "#         print(f\"Merge file {idx + 1} - {indexname}\")\n",
    "#         index = faiss.read_index(os.path.join(index_folder2, indexname))\n",
    "\n",
    "#         num_vectors = index.ntotal\n",
    "#         for i in range(num_vectors):\n",
    "#             vec = index.reconstruct(i).reshape(-1, 384)\n",
    "#             vec = np.array(vec).astype(\"float32\")\n",
    "#             merged_index.add(vec)\n",
    "            \n",
    "#     else:\n",
    "#         indexname = f\"wikipedia_embeddings_collection_{idx + 1}_{filename}.index\"\n",
    "#         print(f\"Merge file {idx + 1} - {indexname}\")\n",
    "#         index = faiss.read_index(os.path.join(index_folder1, indexname))\n",
    "\n",
    "#         num_vectors = index.ntotal\n",
    "#         for i in range(num_vectors):\n",
    "#             vec = index.reconstruct(i).reshape(-1, 384)\n",
    "#             vec = np.array(vec).astype(\"float32\")\n",
    "#             merged_index.add(vec)\n",
    "            \n",
    "#     if (idx + 1) == 12:\n",
    "#         merged_index_path = \"/kaggle/working/merged_2.index\"\n",
    "#         faiss.write_index(merged_index, merged_index_path)\n",
    "\n",
    "#         print(f\"Merged index saved to '{merged_index_path}'\")\n",
    "        \n",
    "#         del merged_index\n",
    "\n",
    "        \n",
    "# merged_index = faiss.IndexFlatL2(384)\n",
    "# for idx, filename in enumerate(file_names):\n",
    "#     if (idx + 1) <= 12:\n",
    "#         continue\n",
    "        \n",
    "#     if (idx + 1) == 20:\n",
    "#         break\n",
    "    \n",
    "#     if (idx + 1) >= 12 and (idx + 1) <= 20:\n",
    "#         indexname = f\"wikipedia_embeddings_collection_{idx + 1}_{filename}.index\"\n",
    "#         print(f\"Merge file {idx + 1} - {indexname}\")\n",
    "#         index = faiss.read_index(os.path.join(index_folder2, indexname))\n",
    "\n",
    "#         num_vectors = index.ntotal\n",
    "#         for i in range(num_vectors):\n",
    "#             vec = index.reconstruct(i).reshape(-1, 384)\n",
    "#             vec = np.array(vec).astype(\"float32\")\n",
    "#             merged_index.add(vec)\n",
    "            \n",
    "#     else:\n",
    "#         indexname = f\"wikipedia_embeddings_collection_{idx + 1}_{filename}.index\"\n",
    "#         print(f\"Merge file {idx + 1} - {indexname}\")\n",
    "#         index = faiss.read_index(os.path.join(index_folder1, indexname))\n",
    "\n",
    "#         num_vectors = index.ntotal\n",
    "#         for i in range(num_vectors):\n",
    "#             vec = index.reconstruct(i).reshape(-1, 384)\n",
    "#             vec = np.array(vec).astype(\"float32\")\n",
    "#             merged_index.add(vec)\n",
    "            \n",
    "#     if (idx + 1) == 19:\n",
    "#         merged_index_path = \"/kaggle/working/merged_3.index\"\n",
    "#         faiss.write_index(merged_index, merged_index_path)\n",
    "\n",
    "#         print(f\"Merged index saved to '{merged_index_path}'\")\n",
    "        \n",
    "#         del merged_index\n",
    "        \n",
    "# merged_index = faiss.IndexFlatL2(384)\n",
    "# for idx, filename in enumerate(file_names):\n",
    "#     if (idx + 1) <= 19:\n",
    "#         continue\n",
    "    \n",
    "#     if (idx + 1) >= 12 and (idx + 1) <= 20:\n",
    "#         indexname = f\"wikipedia_embeddings_collection_{idx + 1}_{filename}.index\"\n",
    "#         print(f\"Merge file {idx + 1} - {indexname}\")\n",
    "#         index = faiss.read_index(os.path.join(index_folder2, indexname))\n",
    "\n",
    "#         num_vectors = index.ntotal\n",
    "#         for i in range(num_vectors):\n",
    "#             vec = index.reconstruct(i).reshape(-1, 384)\n",
    "#             vec = np.array(vec).astype(\"float32\")\n",
    "#             merged_index.add(vec)\n",
    "            \n",
    "#     else:\n",
    "#         indexname = f\"wikipedia_embeddings_collection_{idx + 1}_{filename}.index\"\n",
    "#         print(f\"Merge file {idx + 1} - {indexname}\")\n",
    "#         index = faiss.read_index(os.path.join(index_folder1, indexname))\n",
    "\n",
    "#         num_vectors = index.ntotal\n",
    "#         for i in range(num_vectors):\n",
    "#             vec = index.reconstruct(i).reshape(-1, 384)\n",
    "#             vec = np.array(vec).astype(\"float32\")\n",
    "#             merged_index.add(vec)\n",
    "            \n",
    "#     if (idx + 1) == 28:\n",
    "#         merged_index_path = \"/kaggle/working/merged_4.index\"\n",
    "#         faiss.write_index(merged_index, merged_index_path)\n",
    "\n",
    "#         print(f\"Merged index saved to '{merged_index_path}'\")\n",
    "        \n",
    "#         del merged_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e3d42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T06:58:55.406705Z",
     "iopub.status.busy": "2023-09-09T06:58:55.406195Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merged_index = faiss.IndexFlatL2(384)\n",
    "# # merged_index = faiss.read_index(\"/kaggle/input/wikipedia-embeddings/merged_1.index\")\n",
    "# index_folder = \"/kaggle/input/wikipedia-embeddings\"\n",
    "\n",
    "# for idx, indexname in enumerate(os.listdir(index_folder)):\n",
    "#     print(f\"Merge file {idx + 1} - {indexname}\")\n",
    "#     index = faiss.read_index(os.path.join(index_folder, indexname))\n",
    "\n",
    "#     num_vectors = index.ntotal\n",
    "#     for i in range(num_vectors):\n",
    "#         vec = index.reconstruct(i).reshape(-1, 384)\n",
    "#         vec = np.array(vec).astype(\"float32\")\n",
    "#         merged_index.add(vec)\n",
    "\n",
    "#     del index\n",
    "\n",
    "# merged_index_path = \"/kaggle/working/merged.index\"\n",
    "# faiss.write_index(merged_index, merged_index_path)\n",
    "\n",
    "# print(f\"Merged index saved to '{merged_index_path}'\")"
   ]
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.6.4"
 },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6191.868712,
   "end_time": "2023-09-09T12:09:27.207571",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-09T10:26:15.338859",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
